{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1UF5L11acnAVec5iZTTYHeK3c8ccBoUZm","timestamp":1668784438605},{"file_id":"https://github.com/dtran421/machine-learning-engineering-demo/blob/main/Machine_Learning_Engineering_Demo.ipynb","timestamp":1668629251023}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Machine Learning Engineering Demo\n","\n","In this notebook, we will walk through a simple machine learning project and see how it can be applied to software. This project focuses on identifying whether an email is spam or not (\"ham\" or \"spam\")."],"metadata":{"id":"ahDQxeGhArhk"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"19PHdwE808S3","executionInfo":{"status":"ok","timestamp":1668784557502,"user_tz":300,"elapsed":1110,"user":{"displayName":"Sayyed Hadi Razmjo","userId":"04206113701168650498"}}},"outputs":[],"source":["#@title Import statements for ML-related modules {display-mode: \"form\"}\n","import numpy as np\n","import re\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestRegressor"]},{"cell_type":"markdown","source":["## Training the model\n","In this section, we perform preprocessing on our data and then train the model on this data. Your job here is to run each code cell and understand what is going on."],"metadata":{"id":"qSSuV0HKK56u"}},{"cell_type":"code","source":["#@title Import the Enron Dataset to train the machine learning model {display-mode: \"form\"}\n","DATA_URL = 'https://raw.githubusercontent.com/dtran421/machine-learning-engineering-demo/main/enron_data.csv'\n","df = pd.read_csv(DATA_URL, index_col=0)"],"metadata":{"id":"KjOE3Y9F24Z9","executionInfo":{"status":"ok","timestamp":1668784561803,"user_tz":300,"elapsed":714,"user":{"displayName":"Sayyed Hadi Razmjo","userId":"04206113701168650498"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["#@title Initialize constant variables {display-mode: \"form\"}\n","# these counts will be used later on for shuffling and subsetting the data\n","numTotal    = len(df)\n","numTrain    = int(.8*numTotal)\n","numTest     = numTotal-numTrain\n","\n","# maximum amount of features that we want our feature vectors to contain\n","numFeatures = 3000"],"metadata":{"id":"-k4pM5hW8T7O","executionInfo":{"status":"ok","timestamp":1668784566548,"user_tz":300,"elapsed":215,"user":{"displayName":"Sayyed Hadi Razmjo","userId":"04206113701168650498"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#@title Initialize lists for labels and docs (email messages) {display-mode: \"form\"}\n","#@markdown Labels: 0 = ham (*legitimate*), 1 = spam\n","labels = df['Label']   # list of labels for each email\n","docs   = df['Body']    # list of emails"],"metadata":{"id":"waxDD0x22Tl3","executionInfo":{"status":"ok","timestamp":1668784570923,"user_tz":300,"elapsed":212,"user":{"displayName":"Sayyed Hadi Razmjo","userId":"04206113701168650498"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#@title Initialize preprocessor and vectorizor {display-mode: \"form\"}\n","\n","# this function will be called on each message to preprocess it\n","def preprocess(doc):\n","    # replace all currency signs and some url patterns with special\n","    # tokens as these are useful features.\n","    doc = re.sub('[Â£$]', ' __currency__ ', doc)\n","    doc = re.sub('\\://', ' __url__ ', doc)\n","    doc = doc.lower()\n","    return doc\n","\n","\n","# vectorizer is responsible for converting bodies of text into feature vectors\n","# these vectors are much easier for a machine learning model to deal with\n","vectorizer = CountVectorizer(max_features=numFeatures, preprocessor=preprocess)"],"metadata":{"id":"J5P6x57m6nwv","executionInfo":{"status":"ok","timestamp":1668784575322,"user_tz":300,"elapsed":309,"user":{"displayName":"Sayyed Hadi Razmjo","userId":"04206113701168650498"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#@title Vectorize docs (email messages) {display-mode: \"form\"}\n","# now, we actually perform the conversion from text to feature vectors\n","X = vectorizer.fit_transform(docs)"],"metadata":{"id":"XP2OQIVt_Stl","executionInfo":{"status":"ok","timestamp":1668784581679,"user_tz":300,"elapsed":2056,"user":{"displayName":"Sayyed Hadi Razmjo","userId":"04206113701168650498"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#@title Create data structures to hold data and labels {display-mode: \"form\"}\n","\n","# dense numpy arrays will be easier to work with\n","X = X.toarray()\n","m,n = X.shape\n","y = labels.array\n","\n","# add a column of ones (bias of the hypothesis function)\n","# this is kind of like the y-intercept\n","X = np.column_stack([np.ones(m), X])"],"metadata":{"id":"hDZQQGzP_01G","executionInfo":{"status":"ok","timestamp":1668784583110,"user_tz":300,"elapsed":519,"user":{"displayName":"Sayyed Hadi Razmjo","userId":"04206113701168650498"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["#@title Shuffle datapoints {display-mode: \"form\"}\n","# randomize the indices of our data\n","idx = np.arange(numTotal)\n","np.random.shuffle(idx)"],"metadata":{"id":"JIJE_V4fGhT9","executionInfo":{"status":"ok","timestamp":1668784587368,"user_tz":300,"elapsed":150,"user":{"displayName":"Sayyed Hadi Razmjo","userId":"04206113701168650498"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["#@title Split dataset into training and testing sets (email messages) {display-mode: \"form\"}\n","\n","# apply the randomized indices to our model input\n","X = X[idx,:]\n","y = y[idx]\n","\n","# split into training and testing sets\n","# we have hard coded the split between training and testing to be 80:20\n","train = np.arange(numTrain)\n","test  = numTrain + np.arange(numTest)\n","\n","X_train = X[train,:]\n","y_train = y[train]\n","\n","X_test  = X[test,:]\n","y_test  = y[test]"],"metadata":{"id":"nO3cCOJU_Vh3","executionInfo":{"status":"ok","timestamp":1668784590889,"user_tz":300,"elapsed":207,"user":{"displayName":"Sayyed Hadi Razmjo","userId":"04206113701168650498"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["### Model 1: Random Forest Regressor\n","\n","In this first model, we will walk you through the Random Forest Regressor, a model that averages across many classifying decision trees to come up with a final classification."],"metadata":{"id":"H2hlSUS9txPB"}},{"cell_type":"code","source":["# create a model and then fit it to our data\n","model1 = RandomForestRegressor(max_features=.3, n_estimators=25)\n","model1.fit(X_train, y_train)\n","\n","# feel free to change or add parameters and see how it affects the \n","# training time (very bottom left while running a cell) and model accurracy\n","# as a warning, increasing values too much can greatly increase execution time\n","# docs: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oa-BGNfinwgf","outputId":"99e5f6a7-8ab4-4e24-c66c-930d4a6d6e5b","executionInfo":{"status":"ok","timestamp":1668784612087,"user_tz":300,"elapsed":18128,"user":{"displayName":"Sayyed Hadi Razmjo","userId":"04206113701168650498"}}},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomForestRegressor(max_features=0.3, n_estimators=25)"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# create a prediction for our test data\n","pred_enron = model1.predict(X_test)\n","\n","# now we check to see how well our model works\n","res = np.sum(np.abs(pred_enron - y_test))\n","acc = 100 - (res / numTest * 100)\n","print(f'Model Accuracy: {acc}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4loUlgQQodB8","outputId":"8aebb86a-26dc-4e40-c70c-ebc8960e9419","executionInfo":{"status":"ok","timestamp":1668784615365,"user_tz":300,"elapsed":6,"user":{"displayName":"Sayyed Hadi Razmjo","userId":"04206113701168650498"}}},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Model Accuracy: 92.02%\n"]}]},{"cell_type":"markdown","source":["### Model 2: Logistic Regression\n","\n","That accuracy is okay, but maybe the Random Forest Regressor isn't the best choice. Let's try a Logistic Regression, which is a simple type of linear model that can be used to predict the probability of a binary event occurring. This time, it's your turn to implement the training and testing. You can reference our code above when implementing."],"metadata":{"id":"0_s6nEg_u5Lg"}},{"cell_type":"code","source":["# TODO: create a new model \"model2\" using \"LogisticRegression\" \n","# for params, we recommend using solver='liblinear'\n","# feel free to play around with params to try to get better accuracy\n","\n","\n","# TODO: fit it to our data \"X_train\" and \"y_train\"\n","model2 = LogisticRegression(max_iter=500, solver='liblinear')\n","model2.fit(X_train, y_train)\n","\n","# docs: https://scikit-learn.org/stable/modules/linear_model.html?highlight=logistic+regress#logistic-regression"],"metadata":{"id":"3oTLOjYVFOH5","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d5e80356-cf30-43c5-ac97-a45802c0159f","executionInfo":{"status":"ok","timestamp":1668784774339,"user_tz":300,"elapsed":359,"user":{"displayName":"Sayyed Hadi Razmjo","userId":"04206113701168650498"}}},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LogisticRegression(max_iter=500, solver='liblinear')"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["# TODO: using \"model2\", create a prediction \"pred_enron\" for our test data \"X_test\"\n","pred_enron = model2.predict(X_test)\n","\n","# now we check to see how well our model works\n","res = np.sum(np.abs(pred_enron - y_test))\n","acc = 100 - (res / numTest * 100)\n","print(f'Model Accuracy: {acc}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i8Itp1OVGySu","outputId":"29192213-fcd6-4487-d228-f5a21dda5298","executionInfo":{"status":"ok","timestamp":1668784781821,"user_tz":300,"elapsed":145,"user":{"displayName":"Sayyed Hadi Razmjo","userId":"04206113701168650498"}}},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Model Accuracy: 97.7%\n"]}]},{"cell_type":"markdown","source":["## Try it yourself\n","\n","In this section, we have left out some code necessary for testing out the models (model1 and model2) on a new dataset (Ling Dataset) that they have never seen before. It is up to you to fill in a few lines and create new predictions using the models we trained above."],"metadata":{"id":"lpnduflQBu34"}},{"cell_type":"code","source":["# TODO: read in Ling Dataset CSV from https://raw.githubusercontent.com/dtran421/machine-learning-engineering-demo/main/ling_data.csv\n","DATA_URL = 'https://raw.githubusercontent.com/dtran421/machine-learning-engineering-demo/main/ling_data.csv'\n","df = pd.read_csv(DATA_URL, index_col=0)"],"metadata":{"id":"bMEWNzjWG7hG","executionInfo":{"status":"ok","timestamp":1668784786474,"user_tz":300,"elapsed":205,"user":{"displayName":"Sayyed Hadi Razmjo","userId":"04206113701168650498"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# here, we will perform same preprocessing steps that we did previously\n","numTotal    = len(df)\n","\n","labels = df['Label']   # list of labels for each email\n","docs   = df['Body']    # list of emails\n","\n","# convert the email content to feature vectors\n","X = vectorizer.fit_transform(docs)\n","\n","# read into arrays\n","X = X.toarray()\n","m,n = X.shape\n","y = labels.array\n","\n","# add column of ones\n","X = np.column_stack([np.ones(m), X])"],"metadata":{"id":"nDHCLOeKIzfB","executionInfo":{"status":"ok","timestamp":1668784790984,"user_tz":300,"elapsed":2358,"user":{"displayName":"Sayyed Hadi Razmjo","userId":"04206113701168650498"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["Since our linear regressor had better testing accuracy, let's try that model out first."],"metadata":{"id":"x0vrR6SVFiQW"}},{"cell_type":"code","source":["# TODO: create a prediction \"pred_ling\" using the pre-trained Linear Regressor, \"model2\"\n","# the parameter should be \"X\" this time instead of \"X_test\"\n","pred_ling = model2.predict(X)"],"metadata":{"id":"WXia1oivD-5b","executionInfo":{"status":"ok","timestamp":1668784799174,"user_tz":300,"elapsed":207,"user":{"displayName":"Sayyed Hadi Razmjo","userId":"04206113701168650498"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# compare predicted y to y_tests\n","res = np.sum(np.abs(pred_ling - y))\n","acc = 100 - (res / numTotal * 100)\n","print(f'Model Accuracy {acc}%')"],"metadata":{"id":"KqTAJcjFELYb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668784802453,"user_tz":300,"elapsed":208,"user":{"displayName":"Sayyed Hadi Razmjo","userId":"04206113701168650498"}},"outputId":"0cde0fe5-c263-4cdd-a249-c6146e5f9d3a"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Model Accuracy 23.800383877159305%\n"]}]},{"cell_type":"markdown","source":["Hmm, likely, the accuracy you got here was not very good. In fact, this was even worse than random guessing. This is likely due to overfitting. Additionally, a linear regression may not be the best option, despite the high testing accuracy. Let's look at the random forest regressor now."],"metadata":{"id":"aSsNdAh3Ealz"}},{"cell_type":"code","source":["# TODO: create a prediction \"pred_ling\" using the pre-trained Random Forest Regressor, \"model1\"\n","# the parameter should be \"X\" instead of \"X_test\"\n","pred_ling = model1.predict(X)"],"metadata":{"id":"va6GPsiyI2Hv","executionInfo":{"status":"ok","timestamp":1668784832468,"user_tz":300,"elapsed":320,"user":{"displayName":"Sayyed Hadi Razmjo","userId":"04206113701168650498"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# compare predicted y to y_tests\n","res = np.sum(np.abs(pred_ling - y))\n","acc = 100 - (res / numTotal * 100)\n","print(f'Model Accuracy {acc}%')"],"metadata":{"id":"l8ZvwYycJvOL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7a0b00bb-ae29-4a5e-bf75-32736f91296b","executionInfo":{"status":"ok","timestamp":1668784836557,"user_tz":300,"elapsed":289,"user":{"displayName":"Sayyed Hadi Razmjo","userId":"04206113701168650498"}}},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Model Accuracy 65.70595009596929%\n"]}]},{"cell_type":"markdown","source":["Although still not optimal, this was hopefully a much better result. Despite having lower testing accuracy, the Random Forest Regressor seems like a better model for this particular situation. Scenarios like this are why many types of models should be considered."],"metadata":{"id":"HQMF2l5aF50h"}},{"cell_type":"markdown","source":["## Conclusion\n","\n","Now you've trained and tested a model that can accurately predict whether an email is \"ham\" or \"spam\". Why does this matter and how can it be applied?\n","\n","Let's consider a service like Gmail. As everyone knows, this is an email service provided by Google that has many additional features like a spam inbox that is separate from the main inbox. If users had to manually move spam email to this inbox, it would be a passive pain for them. Instead, Google has a similar machine learning algorithm to the one we created above (except theirs is probably a bit better and more complicated). Like us, they also had to try out multiple models and likely many versions of the same type of model until they found their optimal solution. The algorithm creates a \"prediction\" for every email received by the user and assigns the email to the corresponding inbox. This is exactly what Machine Learning Engineering is!"],"metadata":{"id":"90IXxJN1MEwj"}}]}